{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adda2902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.special import softmax\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f86613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DF_READY = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff713b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TEST_DF_READY:\n",
    "    import os\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "    \n",
    "    from transformers import pipeline\n",
    "    from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0223e0e5",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5552399",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('hugface_sentiment_sent_sim_embs_train.csv') if TEST_DF_READY else pd.read_csv('/data/nlp/train.csv')\n",
    "test = pd.read_csv('hugface_sentiment_sent_sim_embs_test.csv') if TEST_DF_READY else pd.read_csv('/data/nlp/test.csv')\n",
    "sample_sub = pd.read_csv('/data/nlp/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643f97db",
   "metadata": {},
   "source": [
    "# Hugging face pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5604ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pipe_out_to_df(pipe_out, postfix=\"\", pos_label=\"POSITIVE\"):\n",
    "    for idx, l_d in enumerate(pipe_out[0]):\n",
    "        print(l_d)\n",
    "        if l_d['label'] == pos_label:\n",
    "            positive_idx = idx \n",
    "            \n",
    "    return pd.DataFrame({postfix + 'pos_prob': [el[positive_idx]['score'] for el in pipe_out]})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8775b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'NEGATIVE', 'score': 0.2978530824184418}\n",
      "{'label': 'POSITIVE', 'score': 0.7021468877792358}\n",
      "{'label': 'NEGATIVE', 'score': 0.2978561222553253}\n",
      "{'label': 'POSITIVE', 'score': 0.7021438479423523}\n",
      "{'label': 'NEGATIVE', 'score': 0.9954701662063599}\n",
      "{'label': 'POSITIVE', 'score': 0.004529833327978849}\n",
      "{'label': 'NEGATIVE', 'score': 0.9954701662063599}\n",
      "{'label': 'POSITIVE', 'score': 0.004529851954430342}\n",
      "{'label': 'Negative', 'score': 0.2841259241104126}\n",
      "{'label': 'Neutral', 'score': 0.65042644739151}\n",
      "{'label': 'Positive', 'score': 0.06544766575098038}\n",
      "{'label': 'Negative', 'score': 0.2841259241104126}\n",
      "{'label': 'Neutral', 'score': 0.65042644739151}\n",
      "{'label': 'Positive', 'score': 0.06544767320156097}\n",
      "{'label': 'Negative', 'score': 0.007281470112502575}\n",
      "{'label': 'Positive', 'score': 0.992718517780304}\n",
      "{'label': 'Negative', 'score': 0.007281450089067221}\n",
      "{'label': 'Positive', 'score': 0.9927185773849487}\n",
      "{'label': 'LABEL_0', 'score': 0.5602739453315735}\n",
      "{'label': 'LABEL_1', 'score': 0.24404405057430267}\n",
      "{'label': 'LABEL_2', 'score': 0.19568203389644623}\n",
      "{'label': 'LABEL_0', 'score': 0.5602738857269287}\n",
      "{'label': 'LABEL_1', 'score': 0.24404406547546387}\n",
      "{'label': 'LABEL_2', 'score': 0.19568203389644623}\n",
      "{'label': '0', 'score': 0.024455424398183823}\n",
      "{'label': '1', 'score': 0.9755445718765259}\n",
      "{'label': '0', 'score': 0.024455416947603226}\n",
      "{'label': '1', 'score': 0.9755445718765259}\n"
     ]
    }
   ],
   "source": [
    "if not TEST_DF_READY:\n",
    "\n",
    "    CLASSIFIER = pipeline('sentiment-analysis', return_all_scores = True)\n",
    "    train = pd.concat([\n",
    "        train,\n",
    "        convert_pipe_out_to_df(CLASSIFIER(train['email_body'].tolist()), pos_label=\"POSITIVE\", postfix=\"trans_baseline\")\n",
    "    ], axis=1)\n",
    "    test = pd.concat([\n",
    "        test,\n",
    "        convert_pipe_out_to_df(CLASSIFIER(test['email_body'].tolist()), pos_label=\"POSITIVE\", postfix=\"trans_baseline\")\n",
    "    ], axis=1)\n",
    "    \n",
    "    CLASSIFIER = pipeline('sentiment-analysis', model='siebert/sentiment-roberta-large-english', return_all_scores = True)\n",
    "    train = pd.concat([\n",
    "        train,\n",
    "        convert_pipe_out_to_df(CLASSIFIER(train['email_body'].tolist()), pos_label=\"POSITIVE\", postfix=\"siebert_sentiment_roberta_large_english\")\n",
    "    ], axis=1)\n",
    "    test = pd.concat([\n",
    "        test,\n",
    "        convert_pipe_out_to_df(CLASSIFIER(test['email_body'].tolist()), pos_label=\"POSITIVE\", postfix=\"siebert_sentiment_roberta_large_english\")\n",
    "    ], axis=1)\n",
    "    \n",
    "    CLASSIFIER = pipeline('sentiment-analysis', model='cardiffnlp/twitter-xlm-roberta-base-sentiment', return_all_scores = True)\n",
    "    train = pd.concat([\n",
    "        train,\n",
    "        convert_pipe_out_to_df(CLASSIFIER(train['email_body'].tolist()), pos_label=\"Positive\", postfix=\"cardiffnlp_twitter_xlm_roberta_base_sentiment\")\n",
    "    ], axis=1)\n",
    "    test = pd.concat([\n",
    "        test,\n",
    "        convert_pipe_out_to_df(CLASSIFIER(test['email_body'].tolist()), pos_label=\"Positive\", postfix=\"cardiffnlp_twitter_xlm_roberta_base_sentiment\")\n",
    "    ], axis=1)\n",
    "    \n",
    "    CLASSIFIER = pipeline('sentiment-analysis', model='moussaKam/barthez-sentiment-classification', return_all_scores = True)\n",
    "    train = pd.concat([\n",
    "        train,\n",
    "        convert_pipe_out_to_df(CLASSIFIER(train['email_body'].tolist()), pos_label=\"Positive\", postfix=\"moussaKam_barthez_sentiment_classification\")\n",
    "    ], axis=1)\n",
    "    test = pd.concat([\n",
    "        test,\n",
    "        convert_pipe_out_to_df(CLASSIFIER(test['email_body'].tolist()), pos_label=\"Positive\", postfix=\"moussaKam_barthez_sentiment_classification\")\n",
    "    ], axis=1)\n",
    "    \n",
    "    CLASSIFIER = pipeline('sentiment-analysis', model='rohanrajpal/bert-base-multilingual-codemixed-cased-sentiment', return_all_scores = True)\n",
    "    train = pd.concat([\n",
    "        train,\n",
    "        convert_pipe_out_to_df(CLASSIFIER(train['email_body'].tolist()), pos_label=\"LABEL_2\", postfix=\"rohanrajpal_bert_base_multilingual_codemixed-cased_sentiment\")\n",
    "    ], axis=1)\n",
    "    test = pd.concat([\n",
    "        test,\n",
    "        convert_pipe_out_to_df(CLASSIFIER(test['email_body'].tolist()), pos_label=\"LABEL_2\", postfix=\"rohanrajpal_bert_base_multilingual_codemixed-cased_sentiment\")\n",
    "    ], axis=1)\n",
    "    \n",
    "    CLASSIFIER = pipeline('sentiment-analysis', model='abhishek/autonlp-imdb_sentiment_classification-31154', return_all_scores = True)\n",
    "    train = pd.concat([\n",
    "        train,\n",
    "        convert_pipe_out_to_df(CLASSIFIER(train['email_body'].tolist()), pos_label=\"1\", postfix=\"abhishek_autonlp_imdb_sentiment_classification_31154\")\n",
    "    ], axis=1)\n",
    "    test = pd.concat([\n",
    "        test,\n",
    "        convert_pipe_out_to_df(CLASSIFIER(test['email_body'].tolist()), pos_label=\"1\", postfix=\"abhishek_autonlp_imdb_sentiment_classification_31154\")\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d9510c",
   "metadata": {},
   "source": [
    "# Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52d9a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TEST_DF_READY:\n",
    "\n",
    "    SENT_EMBED = SentenceTransformer('paraphrase-mpnet-base-v2', device='cuda')\n",
    "    train_emb = SENT_EMBED.encode(train.email_body)\n",
    "    test_emb = SENT_EMBED.encode(test.email_body)\n",
    "    test['emb_sim_2'] = util.cos_sim(train_emb[0], test_emb)[0,:]\n",
    "    test['emb_sim_3'] = util.cos_sim(train_emb[1], test_emb)[0,:]\n",
    "    test['emb_sim_4'] = util.cos_sim(train_emb[2], test_emb)[0,:]\n",
    "    test['emb_sim_5'] = util.cos_sim(train_emb[3], test_emb)[0,:]\n",
    "    test['emb_sim_1'] = util.cos_sim(train_emb[4], test_emb)[0,:]\n",
    "    test['cos_softmax_sum'] = (softmax(test[['emb_sim_1', 'emb_sim_2', 'emb_sim_3', 'emb_sim_4', 'emb_sim_5',]].values, axis=1) * np.array([[1,2,3,4,5]])).sum(axis=1)\n",
    "\n",
    "    test.to_csv('hugface_sentiment_sent_sim_embs_test.csv', index=False)\n",
    "    train.to_csv('hugface_sentiment_sent_sim_embs_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c915910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>email_body</th>\n",
       "      <th>trans_baselinepos_prob</th>\n",
       "      <th>siebert_sentiment_roberta_large_englishpos_prob</th>\n",
       "      <th>cardiffnlp_twitter_xlm_roberta_base_sentimentpos_prob</th>\n",
       "      <th>moussaKam_barthez_sentiment_classificationpos_prob</th>\n",
       "      <th>rohanrajpal_bert_base_multilingual_codemixed-cased_sentimentpos_prob</th>\n",
       "      <th>abhishek_autonlp_imdb_sentiment_classification_31154pos_prob</th>\n",
       "      <th>emb_sim_2</th>\n",
       "      <th>emb_sim_3</th>\n",
       "      <th>emb_sim_4</th>\n",
       "      <th>emb_sim_5</th>\n",
       "      <th>emb_sim_1</th>\n",
       "      <th>cos_softmax_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hi Don,\\n\\n \\n\\n4pm does not work unfortunatel...</td>\n",
       "      <td>0.702144</td>\n",
       "      <td>0.004530</td>\n",
       "      <td>0.065448</td>\n",
       "      <td>0.992719</td>\n",
       "      <td>0.195682</td>\n",
       "      <td>0.975545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.287977</td>\n",
       "      <td>0.167633</td>\n",
       "      <td>0.182790</td>\n",
       "      <td>0.136230</td>\n",
       "      <td>2.811827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sorry, Greg. I’ve been buried this week. I’m d...</td>\n",
       "      <td>0.013214</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.094949</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.301675</td>\n",
       "      <td>0.992760</td>\n",
       "      <td>0.287956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.213383</td>\n",
       "      <td>0.180342</td>\n",
       "      <td>0.133079</td>\n",
       "      <td>3.001932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey Paul,\\n\\n \\n\\nThanks for the time on the c...</td>\n",
       "      <td>0.024301</td>\n",
       "      <td>0.996394</td>\n",
       "      <td>0.282276</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.053340</td>\n",
       "      <td>0.996837</td>\n",
       "      <td>0.167671</td>\n",
       "      <td>0.213388</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.238051</td>\n",
       "      <td>0.299402</td>\n",
       "      <td>3.177293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Hi,\\n\\n \\n\\nIncluding one of my Admins who wor...</td>\n",
       "      <td>0.971037</td>\n",
       "      <td>0.995294</td>\n",
       "      <td>0.092082</td>\n",
       "      <td>0.999201</td>\n",
       "      <td>0.052842</td>\n",
       "      <td>0.992043</td>\n",
       "      <td>0.108310</td>\n",
       "      <td>0.086292</td>\n",
       "      <td>0.372413</td>\n",
       "      <td>0.078116</td>\n",
       "      <td>0.111501</td>\n",
       "      <td>3.044992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Hello Momin,\\n\\n \\n\\nTo follow up on our last ...</td>\n",
       "      <td>0.042077</td>\n",
       "      <td>0.997270</td>\n",
       "      <td>0.202740</td>\n",
       "      <td>0.998990</td>\n",
       "      <td>0.107590</td>\n",
       "      <td>0.989911</td>\n",
       "      <td>0.243042</td>\n",
       "      <td>0.099824</td>\n",
       "      <td>0.464646</td>\n",
       "      <td>0.133173</td>\n",
       "      <td>0.174200</td>\n",
       "      <td>3.034998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                         email_body  \\\n",
       "0   0  Hi Don,\\n\\n \\n\\n4pm does not work unfortunatel...   \n",
       "1   1  Sorry, Greg. I’ve been buried this week. I’m d...   \n",
       "2   2  Hey Paul,\\n\\n \\n\\nThanks for the time on the c...   \n",
       "3   3  Hi,\\n\\n \\n\\nIncluding one of my Admins who wor...   \n",
       "4   4  Hello Momin,\\n\\n \\n\\nTo follow up on our last ...   \n",
       "\n",
       "   trans_baselinepos_prob  siebert_sentiment_roberta_large_englishpos_prob  \\\n",
       "0                0.702144                                         0.004530   \n",
       "1                0.013214                                         0.002396   \n",
       "2                0.024301                                         0.996394   \n",
       "3                0.971037                                         0.995294   \n",
       "4                0.042077                                         0.997270   \n",
       "\n",
       "   cardiffnlp_twitter_xlm_roberta_base_sentimentpos_prob  \\\n",
       "0                                           0.065448       \n",
       "1                                           0.094949       \n",
       "2                                           0.282276       \n",
       "3                                           0.092082       \n",
       "4                                           0.202740       \n",
       "\n",
       "   moussaKam_barthez_sentiment_classificationpos_prob  \\\n",
       "0                                           0.992719    \n",
       "1                                           0.000048    \n",
       "2                                           0.002769    \n",
       "3                                           0.999201    \n",
       "4                                           0.998990    \n",
       "\n",
       "   rohanrajpal_bert_base_multilingual_codemixed-cased_sentimentpos_prob  \\\n",
       "0                                           0.195682                      \n",
       "1                                           0.301675                      \n",
       "2                                           0.053340                      \n",
       "3                                           0.052842                      \n",
       "4                                           0.107590                      \n",
       "\n",
       "   abhishek_autonlp_imdb_sentiment_classification_31154pos_prob  emb_sim_2  \\\n",
       "0                                           0.975545              1.000000   \n",
       "1                                           0.992760              0.287956   \n",
       "2                                           0.996837              0.167671   \n",
       "3                                           0.992043              0.108310   \n",
       "4                                           0.989911              0.243042   \n",
       "\n",
       "   emb_sim_3  emb_sim_4  emb_sim_5  emb_sim_1  cos_softmax_sum  \n",
       "0   0.287977   0.167633   0.182790   0.136230         2.811827  \n",
       "1   1.000000   0.213383   0.180342   0.133079         3.001932  \n",
       "2   0.213388   1.000000   0.238051   0.299402         3.177293  \n",
       "3   0.086292   0.372413   0.078116   0.111501         3.044992  \n",
       "4   0.099824   0.464646   0.133173   0.174200         3.034998  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3aa68ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>email_body</th>\n",
       "      <th>trans_baselinepos_prob</th>\n",
       "      <th>siebert_sentiment_roberta_large_englishpos_prob</th>\n",
       "      <th>cardiffnlp_twitter_xlm_roberta_base_sentimentpos_prob</th>\n",
       "      <th>moussaKam_barthez_sentiment_classificationpos_prob</th>\n",
       "      <th>rohanrajpal_bert_base_multilingual_codemixed-cased_sentimentpos_prob</th>\n",
       "      <th>abhishek_autonlp_imdb_sentiment_classification_31154pos_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Hi Don,\\n\\n \\n\\n4pm does not work unfortunatel...</td>\n",
       "      <td>0.702147</td>\n",
       "      <td>0.004530</td>\n",
       "      <td>0.065448</td>\n",
       "      <td>0.992719</td>\n",
       "      <td>0.195682</td>\n",
       "      <td>0.975545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Sorry, Greg. I’ve been buried this week. I’m d...</td>\n",
       "      <td>0.013214</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.094949</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.301676</td>\n",
       "      <td>0.992760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Hey Paul,\\n\\n \\n\\nThanks for the time on the c...</td>\n",
       "      <td>0.024301</td>\n",
       "      <td>0.996394</td>\n",
       "      <td>0.282276</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.053340</td>\n",
       "      <td>0.996837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect - I see it.\\n\\nRunning a test now.\\n</td>\n",
       "      <td>0.999503</td>\n",
       "      <td>0.996130</td>\n",
       "      <td>0.841748</td>\n",
       "      <td>0.988856</td>\n",
       "      <td>0.970645</td>\n",
       "      <td>0.994174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>We are not using this and did not authorize re...</td>\n",
       "      <td>0.010381</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.041250</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.085989</td>\n",
       "      <td>0.987938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                         email_body  \\\n",
       "0          2  Hi Don,\\n\\n \\n\\n4pm does not work unfortunatel...   \n",
       "1          3  Sorry, Greg. I’ve been buried this week. I’m d...   \n",
       "2          4  Hey Paul,\\n\\n \\n\\nThanks for the time on the c...   \n",
       "3          5       Perfect - I see it.\\n\\nRunning a test now.\\n   \n",
       "4          1  We are not using this and did not authorize re...   \n",
       "\n",
       "   trans_baselinepos_prob  siebert_sentiment_roberta_large_englishpos_prob  \\\n",
       "0                0.702147                                         0.004530   \n",
       "1                0.013214                                         0.002396   \n",
       "2                0.024301                                         0.996394   \n",
       "3                0.999503                                         0.996130   \n",
       "4                0.010381                                         0.000649   \n",
       "\n",
       "   cardiffnlp_twitter_xlm_roberta_base_sentimentpos_prob  \\\n",
       "0                                           0.065448       \n",
       "1                                           0.094949       \n",
       "2                                           0.282276       \n",
       "3                                           0.841748       \n",
       "4                                           0.041250       \n",
       "\n",
       "   moussaKam_barthez_sentiment_classificationpos_prob  \\\n",
       "0                                           0.992719    \n",
       "1                                           0.000048    \n",
       "2                                           0.002769    \n",
       "3                                           0.988856    \n",
       "4                                           0.000562    \n",
       "\n",
       "   rohanrajpal_bert_base_multilingual_codemixed-cased_sentimentpos_prob  \\\n",
       "0                                           0.195682                      \n",
       "1                                           0.301676                      \n",
       "2                                           0.053340                      \n",
       "3                                           0.970645                      \n",
       "4                                           0.085989                      \n",
       "\n",
       "   abhishek_autonlp_imdb_sentiment_classification_31154pos_prob  \n",
       "0                                           0.975545             \n",
       "1                                           0.992760             \n",
       "2                                           0.996837             \n",
       "3                                           0.994174             \n",
       "4                                           0.987938             "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
